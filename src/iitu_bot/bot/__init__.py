"""Telegram bot module with RAG integration"""

import asyncio
import logging
from aiogram import Bot, Dispatcher, F
from aiogram.types import Message
from aiogram.filters import Command, CommandStart
import google.generativeai as genai
from typing import Dict, List, Optional
from ..config import Config
from ..database import VectorDatabase

logger = logging.getLogger(__name__)

class IITUTelegramBot:
    """IITU Telegram bot with RAG capabilities"""
    
    def __init__(self):
        # Initialize bot and dispatcher
        self.bot = Bot(token=Config.TELEGRAM_BOT_TOKEN)
        self.dp = Dispatcher()
        
        # Initialize Gemini AI
        genai.configure(api_key=Config.GEMINI_API_KEY)
        self.ai_model = genai.GenerativeModel('gemini-pro')
        
        # Initialize vector database
        self.vector_db = VectorDatabase()
        
        # User sessions for retry logic
        self.user_sessions: Dict[int, Dict] = {}
        
        # Register handlers
        self._register_handlers()
        
        logger.info("IITU Telegram Bot initialized")
    
    def _register_handlers(self):
        """Register message handlers"""
        
        @self.dp.message(CommandStart())
        async def start_handler(message: Message):
            await self.handle_start(message)
        
        @self.dp.message(Command('help'))
        async def help_handler(message: Message):
            await self.handle_help(message)
        
        @self.dp.message(Command('return'))
        async def return_handler(message: Message):
            await self.handle_return(message)
        
        @self.dp.message(F.text)
        async def text_handler(message: Message):
            await self.handle_text(message)
    
    async def handle_start(self, message: Message):
        """Handle /start command"""
        welcome_text = """
ðŸŽ“ Ð”Ð¾Ð±Ñ€Ð¾ Ð¿Ð¾Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒ Ð² IITU Assistant!

Ð¯ â€” Ð²Ð°Ñˆ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ð°Ð±Ð¸Ñ‚ÑƒÑ€Ð¸ÐµÐ½Ñ‚Ð¾Ð² Ð¸ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð¾Ð² ÐœÐµÐ¶Ð´ÑƒÐ½Ð°Ñ€Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¹ (IITU).

Ð¯ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ð²Ð°Ð¼ Ñ:
â€¢ Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ Ñ„Ð°ÐºÑƒÐ»ÑŒÑ‚ÐµÑ‚Ð°Ñ… Ð¸ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑÑ…
â€¢ ÐŸÑ€Ð¾Ñ†ÐµÐ´ÑƒÑ€Ð°Ñ… Ð¿Ð¾ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸Ñ
â€¢ Ð Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ð¸ Ð¸ ÑƒÑ‡ÐµÐ±Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°Ñ…
â€¢ ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸
â€¢ ÐÐ¾Ð²Ð¾ÑÑ‚ÑÑ… ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð°
â€¢ Ð˜ Ð¼Ð½Ð¾Ð³Ð¸Ð¼ Ð´Ñ€ÑƒÐ³Ð¸Ð¼!

ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð·Ð°Ð´Ð°Ð¹Ñ‚Ðµ ÑÐ²Ð¾Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð¸ Ñ Ð¿Ð¾ÑÑ‚Ð°Ñ€Ð°ÑŽÑÑŒ Ð´Ð°Ñ‚ÑŒ Ð²Ð°Ð¼ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð¸ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚.

Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ /help Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸.
        """
        
        await message.answer(welcome_text)
        
        # Initialize user session
        self.user_sessions[message.from_user.id] = {
            'retry_count': 0,
            'last_query': None,
            'context': []
        }
    
    async def handle_help(self, message: Message):
        """Handle /help command"""
        help_text = """
ðŸ“– IITU Assistant - Ð¡Ð¿Ñ€Ð°Ð²ÐºÐ°

ðŸ” ÐšÐ°Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð±Ð¾Ñ‚Ð°:
â€¢ Ð—Ð°Ð´Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼, ÐºÐ°Ð·Ð°Ñ…ÑÐºÐ¾Ð¼ Ð¸Ð»Ð¸ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ
â€¢ Ð¯ Ð¾Ñ‚Ð²ÐµÑ‡Ñƒ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾Ð± IITU
â€¢ Ð•ÑÐ»Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ /return Ð´Ð»Ñ ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð¸Ñ

ðŸ¤– Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹:
/start - ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ Ñ Ð±Ð¾Ñ‚Ð¾Ð¼
/help - ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÑ‚Ñƒ ÑÐ¿Ñ€Ð°Ð²ÐºÑƒ
/return - ÐŸÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ (Ð´Ð¾ 3 Ñ€Ð°Ð·)

ðŸ’¡ ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð²:
â€¢ "ÐšÐ°ÐºÐ¸Ðµ Ñ„Ð°ÐºÑƒÐ»ÑŒÑ‚ÐµÑ‚Ñ‹ ÐµÑÑ‚ÑŒ Ð² IITU?"
â€¢ "ÐšÐ°Ðº Ð¿Ð¾ÑÑ‚ÑƒÐ¿Ð¸Ñ‚ÑŒ Ð² ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚?"
â€¢ "Ð Ð°ÑÑÐºÐ°Ð¶Ð¸ Ð¾ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ IT"
â€¢ "ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ñ€Ð¸ÐµÐ¼Ð½Ð¾Ð¹ ÐºÐ¾Ð¼Ð¸ÑÑÐ¸Ð¸"

Ð•ÑÐ»Ð¸ Ñƒ Ð²Ð°Ñ ÐµÑÑ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¸Ð»Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ, ÑÐ²ÑÐ¶Ð¸Ñ‚ÐµÑÑŒ Ñ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸ÐµÐ¹ IITU.
        """
        
        await message.answer(help_text)
    
    async def handle_return(self, message: Message):
        """Handle /return command for query refinement"""
        user_id = message.from_user.id
        
        if user_id not in self.user_sessions:
            await message.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ Ð¼Ð¾Ð³ ÐµÐ³Ð¾ Ð¿ÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ.")
            return
        
        session = self.user_sessions[user_id]
        
        if not session['last_query']:
            await message.answer("ÐÐµÑ‚ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÐµÐ³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²ÐºÐ¸.")
            return
        
        if session['retry_count'] >= Config.MAX_RETRIES:
            await message.answer("Ð”Ð¾ÑÑ‚Ð¸Ð³Ð½ÑƒÑ‚Ð¾ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº Ð¿ÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²ÐºÐ¸. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð·Ð°Ð´Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾-Ð´Ñ€ÑƒÐ³Ð¾Ð¼Ñƒ.")
            return
        
        session['retry_count'] += 1
        
        # Refine the query using AI
        refined_query = await self.refine_query(session['last_query'], session['context'])
        
        await message.answer(f"ðŸ”„ ÐŸÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÑŽ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ñ€Ð¾Ñ (Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ° {session['retry_count']})...")
        
        # Process the refined query
        await self.process_user_query(message, refined_query, is_refined=True)
    
    async def handle_text(self, message: Message):
        """Handle text messages"""
        user_query = message.text.strip()
        
        if not user_query:
            await message.answer("ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð·Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð²Ð°Ñˆ Ð²Ð¾Ð¿Ñ€Ð¾Ñ.")
            return
        
        # Initialize session if not exists
        user_id = message.from_user.id
        if user_id not in self.user_sessions:
            self.user_sessions[user_id] = {
                'retry_count': 0,
                'last_query': None,
                'context': []
            }
        
        # Reset retry count for new query
        self.user_sessions[user_id]['retry_count'] = 0
        self.user_sessions[user_id]['last_query'] = user_query
        
        await self.process_user_query(message, user_query)
    
    async def process_user_query(self, message: Message, query: str, is_refined: bool = False):
        """Process user query with RAG"""
        try:
            # Show typing action
            await self.bot.send_chat_action(message.chat.id, 'typing')
            
            # Search in knowledge base
            search_results = self.vector_db.search(query, n_results=5)
            
            user_id = message.from_user.id
            session = self.user_sessions[user_id]
            
            if search_results and self.vector_db.is_relevant(query):
                # Generate response using RAG
                response = await self.generate_rag_response(query, search_results)
                
                # Add to context
                session['context'].append({
                    'query': query,
                    'response': response,
                    'source': 'rag'
                })
                
            else:
                # Generate general response
                response = await self.generate_general_response(query)
                
                # Add to context
                session['context'].append({
                    'query': query,
                    'response': response,
                    'source': 'general'
                })
            
            # Keep only last 5 interactions in context
            if len(session['context']) > 5:
                session['context'] = session['context'][-5:]
            
            await message.answer(response)
            
        except Exception as e:
            logger.error(f"Error processing query: {str(e)}")
            await message.answer("Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð¿Ñ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.")
    
    async def generate_rag_response(self, query: str, search_results: List[Dict]) -> str:
        """Generate response using RAG"""
        # Prepare context from search results
        context_chunks = []
        for result in search_results:
            content = result.get('content', '')
            metadata = result.get('metadata', {})
            source_info = f"Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº: {metadata.get('page_title', 'ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾')}"
            context_chunks.append(f"{content}\n({source_info})")
        
        context = "\n\n---\n\n".join(context_chunks)
        
        prompt = f"""
        Ð¢Ñ‹ â€” ÐÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð¾Ð² Ð¸ Ð°Ð±Ð¸Ñ‚ÑƒÑ€Ð¸ÐµÐ½Ñ‚Ð¾Ð² IITU. Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ.

        ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð°:
        1. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¢ÐžÐ›Ð¬ÐšÐž Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¸Ð· Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
        2. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ Ñ‡ÐµÑ‚ÐºÐ¾
        3. Ð•ÑÐ»Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾, ÑÐºÐ°Ð¶Ð¸ Ð¾Ð± ÑÑ‚Ð¾Ð¼ Ñ‡ÐµÑÑ‚Ð½Ð¾
        4. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐ¹ ÑÐ·Ñ‹Ðº Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        5. Ð‘ÑƒÐ´ÑŒ Ð²ÐµÐ¶Ð»Ð¸Ð²Ñ‹Ð¼ Ð¸ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¼
        6. ÐÐµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð»Ð¸ÑˆÐ½Ð¸Ñ… ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² Ð¸Ð»Ð¸ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹

        ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹ IITU:
        {context}

        Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {query}

        ÐžÑ‚Ð²ÐµÑ‚:
        """
        
        try:
            response = self.ai_model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            logger.error(f"Error generating RAG response: {str(e)}")
            return "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÑ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸."
    
    async def generate_general_response(self, query: str) -> str:
        """Generate general response when no relevant knowledge found"""
        prompt = f"""
        Ð¢Ñ‹ â€” ÐÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð¾Ð² Ð¸ Ð°Ð±Ð¸Ñ‚ÑƒÑ€Ð¸ÐµÐ½Ñ‚Ð¾Ð² IITU. ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð·Ð°Ð´Ð°Ð» Ð²Ð¾Ð¿Ñ€Ð¾Ñ, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð½Ðµ ÑÐ²ÑÐ·Ð°Ð½ Ñ Ð±Ð°Ð·Ð¾Ð¹ Ð·Ð½Ð°Ð½Ð¸Ð¹ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð°.

        ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð°:
        1. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð² Ñ€Ð°Ð¼ÐºÐ°Ñ… ÑÐ²Ð¾ÐµÐ¹ Ñ€Ð¾Ð»Ð¸ ÐºÐ°Ðº Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ IITU
        2. Ð•ÑÐ»Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð½Ðµ ÑÐ²ÑÐ·Ð°Ð½ Ñ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð¾Ð¼, Ð²ÐµÐ¶Ð»Ð¸Ð²Ð¾ Ð½Ð°Ð¿Ñ€Ð°Ð²ÑŒ Ðº Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ð¼ Ñ‚ÐµÐ¼Ð°Ð¼
        3. Ð‘ÑƒÐ´ÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¼ Ð¸ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¼
        4. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐ¹ ÑÐ·Ñ‹Ðº Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        5. ÐŸÑ€ÐµÐ´Ð»Ð°Ð³Ð°Ð¹ Ð¾Ð±Ñ€Ð°Ñ‚Ð¸Ñ‚ÑŒÑÑ Ðº Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°Ð¼ Ð¿Ñ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸

        Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {query}

        ÐžÑ‚Ð²ÐµÑ‚:
        """
        
        try:
            response = self.ai_model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            logger.error(f"Error generating general response: {str(e)}")
            return "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ñ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ñ IITU. ÐžÐ±Ñ€Ð°Ñ‚Ð¸Ñ‚ÐµÑÑŒ Ðº Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ ÑÐ°Ð¹Ñ‚Ñƒ iitu.edu.kz Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹."
    
    async def refine_query(self, original_query: str, context: List[Dict]) -> str:
        """Refine user query using AI"""
        context_text = ""
        if context:
            recent_context = context[-3:]  # Use last 3 interactions
            for item in recent_context:
                context_text += f"Ð—Ð°Ð¿Ñ€Ð¾Ñ: {item['query']}\nÐžÑ‚Ð²ÐµÑ‚: {item['response'][:200]}...\n\n"
        
        prompt = f"""
        ÐŸÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐ¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð±Ð¾Ð»ÐµÐµ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹ IITU.

        Ð˜ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ: {original_query}

        ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ñ… Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹:
        {context_text}

        Ð¡Ð¾Ð·Ð´Ð°Ð¹ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½ÑƒÑŽ Ð²ÐµÑ€ÑÐ¸ÑŽ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ:
        1. Ð‘Ð¾Ð»ÐµÐµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð°Ñ Ð¸ Ñ‡ÐµÑ‚ÐºÐ°Ñ
        2. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ñ IITU
        3. Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð²
        4. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ ÑÐ·Ñ‹Ðº Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°

        ÐŸÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ:
        """
        
        try:
            response = self.ai_model.generate_content(prompt)
            refined = response.text.strip()
            logger.info(f"Query refined: '{original_query}' -> '{refined}'")
            return refined
        except Exception as e:
            logger.error(f"Error refining query: {str(e)}")
            return original_query
    
    async def start_polling(self):
        """Start bot polling"""
        logger.info("Starting IITU Telegram Bot...")
        await self.dp.start_polling(self.bot)
    
    async def stop(self):
        """Stop the bot"""
        await self.bot.session.close()
        logger.info("IITU Telegram Bot stopped")